{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit16bfe68ae12841c89130860605802ebe",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WikiArticleXmlHandler import WikiArticleXmlHandler\n",
    "from WikiDataXmlHandler import WikiDataXmlHandler\n",
    "import xml.sax\n",
    "import mwparserfromhell\n",
    "import stanfordnlp\n",
    "\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "import Utils\n",
    "\n",
    "from ProcessArticle import ProcessArticle"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIKIDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./1.wikidata/wikidatawiki-latest-pages-articles-multistream1.xml-p1p235321.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Started processing: ./1.wikidata/wikidatawiki-latest-pages-articles-multistream1.xml-p1p235321.bz2\n\nWall time: 421 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "handler = WikiDataXmlHandler(\"./askjh.csv\")\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "print(\"Started processing: {}\\n\".format(file))\n",
    "for line in subprocess.Popen([\"bzcat\"],\n",
    "                        stdin=open(file),\n",
    "                        stdout=subprocess.PIPE).stdout:\n",
    "    \n",
    "    if handler._counter > 5: break\n",
    "    parser.feed(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Q22\nQ22\nQ22\nQ22\nQ22\nQ22\n"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(handler._values[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "a = json.loads(handler._values[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['type', 'id', 'labels', 'descriptions', 'aliases', 'claims', 'sitelinks'])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['P2924', 'P1082', 'P1667', 'P1151', 'P1546', 'P5125', 'P349', 'P38', 'P1566', 'P227', 'P3896', 'P1792', 'P2938', 'P2581', 'P2633', 'P1313', 'P3417', 'P417', 'P17', 'P3219', 'P1705', 'P2959', 'P3106', 'P982', 'P94', 'P486', 'P85', 'P418', 'P4212', 'P935', 'P194', 'P37', 'P605', 'P2184', 'P1365', 'P214', 'P300', 'P30', 'P36', 'P856', 'P237', 'P1549', 'P2997', 'P402', 'P1245', 'P691', 'P3241', 'P5905', 'P998', 'P1225', 'P910', 'P3612', 'P35', 'P1791', 'P242', 'P836', 'P1036', 'P2046', 'P3120', 'P6', 'P2163', 'P4427', 'P5573', 'P1417', 'P4839', 'P948', 'P1740', 'P208', 'P1830', 'P1465', 'P1711', 'P2347', 'P3722', 'P1906', 'P1296', 'P373', 'P78', 'P47', 'P31', 'P610', 'P1464', 'P4672', 'P3222', 'P421', 'P3616', 'P5247', 'P150', 'P646', 'P244', 'P163', 'P625', 'P131', 'P1343', 'P41', 'P5019', 'P6573', 'P4801', 'P706', 'P5198', 'P2936', 'P2132', 'P2131', 'P6404', 'P7352', 'P7471'])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"claims\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'mainsnak': {'snaktype': 'value',\n  'property': 'P31',\n  'hash': '74f35128188f12ab9fd1c1948fd0db1ecb98dc76',\n  'datavalue': {'value': {'entity-type': 'item',\n    'numeric-id': 3336843,\n    'id': 'Q3336843'},\n   'type': 'wikibase-entityid'}},\n 'type': 'statement',\n 'id': 'q22$A821BE15-C339-44BC-9DF7-BC573756C882',\n 'rank': 'preferred'}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(a[\"claims\"][\"P31\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wikidata instanceof\n",
    "a[\"claims\"][\"P31\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a[\"claims\"][\"P31\"])):\n",
    "    print(a[\"claims\"][\"P31\"][i][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"|\".join([a[\"claims\"][\"P31\"][i][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] for i in range(len(a[\"claims\"][\"P31\"]))])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARTICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Use device: cpu\n---\nLoading: tokenize\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n---\nLoading: pos\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n---\nLoading: lemma\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\nBuilding an attentional Seq2Seq model...\nUsing a Bi-LSTM encoder\nUsing soft attention for LSTM.\nFinetune all embeddings.\n[Running seq2seq lemmatizer with edit classifier]\n---\nLoading: depparse\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_parser.pt', 'pretrain_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\nDone loading processors!\n---\n"
    }
   ],
   "source": [
    "infoboxes = pd.read_csv(\"./2.data/infobox-list.csv\")[\"infobox template name\"].values.tolist()\n",
    "out_file = \"./saved/debug.csv\"\n",
    "\n",
    "nlp = stanfordnlp.Pipeline(models_dir=\"./stanfordnlp_resources/\", use_gpu=False);\n",
    "\n",
    "func = ProcessArticle(infoboxes, nlp=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\nWall time: 4.24 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "file = \"./test_data/test.xml\"\n",
    "\n",
    "handler = WikiArticleXmlHandler(out_file, func, 1000)\n",
    "handler._DEBUG = True\n",
    "\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "for line in open(file, \"r\", encoding=\"utf8\"):\n",
    "    parser.feed(line)\n",
    "\n",
    "# handler.write_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.read_csv(out_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df[n_df.title.str.contains(\"(?i)cobol\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, a in enumerate(handler._data):\n",
    "    if a[0] == \"List of artificial intelligence projects\":\n",
    "        print(\"{}: {}\".format(i, a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0: Abraham Lincoln\n1: Apollo\n2: Apollo program\n"
    }
   ],
   "source": [
    "for i, a in enumerate(handler._data):\n",
    "    # if a[0] == \"COBOL\":\n",
    "    print(\"{}: {}\".format(i, a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = handler._data[1]\n",
    "text = handler._text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['type:Greek',\n 'name:Apollo',\n 'image:File:Apollo of the Belvedere.jpg',\n 'alt:',\n 'caption:Apollo Belvedere, c. 120–140 CE',\n 'god_of:God of the Sun, light, oracles, knowledge, healing, diseases, music, poetry, songs, dance, archery, herds and flocks,  and protection of young',\n 'abode:Mount Olympus',\n 'symbol:Lyre, laurel wreath, python, raven, swan, bow and arrows',\n 'consort:',\n 'parents:Zeus and Leto',\n 'siblings:Artemis, Aeacus, Angelos, Aphrodite, Ares, Athena, Dionysus, Eileithyia, Enyo, Eris, Ersa, Hebe, Helen of Troy, Hephaestus, Heracles, Hermes, Minos, Pandia, Persephone, Perseus, Rhadamanthus, the Graces, the Horae, the Litae, the Muses, the Moirai',\n 'children:Asclepius, Aristaeus, Corybantes, Hymenaeus, Ialemus, , Apollonis, Borysthenis, Cephisso, Agreus, Amphiaraus, Amphissus, Amphithemis, Anius, Apis, Arabus, Centaurus, Ceos, Chaeron, Chios, Chariclo, Chrysorrhoas, Coronus, Cycnus, Cydon, Delphus, Dorus, Dryops, Eleuther, Epidaurus, Eriopis, Erymanthus, Eurydice, Hector, Iamus, Idmon, Ileus, Ismenus, Laodocus, Lapithus, Linus, Linus of Thrace, Lycomedes, Lycorus, Marathus, Melaneus, Melite, Miletus, Mopsus, Naxos, Oaxes, Oncius, Orpheus, Tenes, Troilus, Parthenos, Phagrus, Phemonoe, Philammon, Phylacides, Phylander, Polypoetes, Syrus, Tenerus, Trophonius, Zeuxippus',\n 'mount:']"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page[4].split(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoboxes = pd.read_csv(\"./saved/infobox-list.csv\")[\"infobox template name\"].values.tolist()\n",
    "cols = [\"title\", \"type\", \"def words\", \"infobox_name\", \"infobox\", \"categories\",\"wikilinks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = mwparserfromhell.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Apollo is one of the most important and complex of the Olympian deities in classical Greek and Roman religion and Greek and Roman mythology. The national divinity of the Greeks, Apollo has been recognized as a god of archery, music and dance, truth and prophecy, healing and diseases, the Sun and light, poetry, and more. He is the son of Zeus and Leto, and the twin brother of Artemis, goddess of the hunt. Seen as the most beautiful god and the ideal of the kouros (ephebe, or a beardless, athletic youth), Apollo is considered to be the most Greek of all the gods. Apollo is known in Greek-influenced Etruscan mythology as Apulu. Krauskopf, I. 2006. \"The Grave and Beyond.\" The Religion of the Etruscans. edited by N. de Grummond and E. Simon. Austin: University of Texas Press. p. vii, p. 73-75.'"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = wiki.strip_code().split(\"\\n\")\n",
    "a = [\" \".join(Utils.cleanhtml(x.strip()).split()) for x in a if not x.isspace() and x != \"\"]\n",
    "a = a[1] # 1st paragraph\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Use device: cpu\n---\nLoading: tokenize\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n---\nLoading: pos\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n---\nLoading: lemma\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\nBuilding an attentional Seq2Seq model...\nUsing a Bi-LSTM encoder\nUsing soft attention for LSTM.\nFinetune all embeddings.\n[Running seq2seq lemmatizer with edit classifier]\n---\nLoading: depparse\nWith settings:\n{'model_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt_parser.pt', 'pretrain_path': './stanfordnlp_resources/en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\nDone loading processors!\n---\n"
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(models_dir=\"./stanfordnlp_resources/\", use_gpu=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
    }
   ],
   "source": [
    "doc = nlp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = doc.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Word index=13;text=deities;lemma=deity;upos=NOUN;xpos=NNS;feats=Number=Plur;governor=9;dependency_relation=obl>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "months_choices = list()\n",
    "for i in range(1,13):\n",
    "    months_choices.append((i, datetime.date(2008, i, 1).strftime('%B')))\n",
    "\n",
    "months_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "definitions = []\n",
    "# no_no = [\"punct\", \"nummod\", \"appos\", \"det\", \"nmod:poss\", \"cop\", \"cc\", \"nsubj\", \"case\"]\n",
    "no_no = [\"punct\", \"nummod\", \"appos\", \"det\"]\n",
    "months = [datetime.date(2008, i, 1).strftime(\"%B\").lower() for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "index\tlemma\t\t\tgovernor\t\t\ttype\n\n 1\tApollo\t\t\tone\t\t\tnsubj\n 2\tbe\t\t\tone\t\t\tcop\n 3\tone\t\t\troot\t\t\troot\n 4\tof\t\t\timportant\t\t\tcase\n 6\tmost\t\t\timportant\t\t\tadvmod\n 7\timportant\t\t\tone\t\t\tnmod\n 8\tand\t\t\tcomplex\t\t\tcc\n 9\tcomplex\t\t\timportant\t\t\tconj\n10\tof\t\t\tdeity\t\t\tcase\n12\tolympian\t\t\tdeity\t\t\tcompound\n13\tdeity\t\t\tcomplex\t\t\tobl\n14\tin\t\t\treligion\t\t\tcase\n15\tclassical\t\t\treligion\t\t\tamod\n16\tGreek\t\t\treligion\t\t\tamod\n17\tand\t\t\tRoman\t\t\tcc\n18\tRoman\t\t\tGreek\t\t\tconj\n19\treligion\t\t\tdeity\t\t\tnmod\n20\tand\t\t\tmythology\t\t\tcc\n21\tGreek\t\t\tmythology\t\t\tamod\n22\tand\t\t\tRoman\t\t\tcc\n23\tRoman\t\t\tGreek\t\t\tconj\n24\tmythology\t\t\treligion\t\t\tconj\n"
    }
   ],
   "source": [
    "print(\"index\\tlemma\\t\\t\\tgovernor\\t\\t\\ttype\\n\")\n",
    "for word in sentence.words:\n",
    "    index = word.index.rjust(2)\n",
    "    word_lemma = word.lemma\n",
    "    governor = sentence.words[word.governor-1].lemma if word.governor > 0 else \"root\"\n",
    "    deprel = word.dependency_relation\n",
    "\n",
    "    if deprel in no_no or word_lemma.lower() in months:\n",
    "        continue\n",
    "\n",
    "    print(\"{}\\t{}\\t\\t\\t{}\\t\\t\\t{}\".format(index, word_lemma, governor, deprel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(word, be_word):\n",
    "    index = -1\n",
    "    target_index = be_word.governor\n",
    "    while(index != target_index):\n",
    "        index = word.governor\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "set()"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes_yes = [\"nmod\", \"compound\", \"obl\"]\n",
    "be_index = None\n",
    "be_gov = None\n",
    "\n",
    "bag = set()\n",
    "for word in sentence.words:\n",
    "    index = word.index.rjust(2)\n",
    "    word_lemma = word.lemma\n",
    "    governor = sentence.words[word.governor-1].lemma if word.governor > 0 else \"root\"\n",
    "    deprel = word.dependency_relation\n",
    "\n",
    "    if word.lemma == \"be\":\n",
    "        be = word\n",
    "        # bag.add(sentence.words[be_gov - 1].lemma)\n",
    "        break\n",
    "\n",
    "# now find the realted words with the be lemma\n",
    "for word in sentence.words:\n",
    "    if word.governor == be_gov and word.dependency_relation in [\"amod\", \"conj\", \"compound\"]and word.xpos in [\"NNS\", \"NN\"] and word.upos == \"NOUN\":\n",
    "        bag.add(word.lemma)\n",
    "\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Word index=9;text=complex;lemma=complex;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=7;dependency_relation=conj>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} {} {}\".format(be_index, be_gov, be_deprel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tags\n",
    "print(\" \". join([\"{} ({})\".format(word.text, word.upos) for word in sentence.words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sentence.tokens[14].words:\n",
    "    if word.lemma in [\"be\"]:\n",
    "        print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.tokens[14].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[f\"index: {word.index.rjust(2)}\\tword: {word.text.ljust(11)}\\tgovernor index: {word.governor}\\tgovernor: {(sentence.words[word.governor-1].text if word.governor > 0 else 'root').ljust(11)}\\tdeprel: {word.dependency_relation}\" for word in sentence.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \". join([\"{} ({} - {})\".format(word.text, word.upos, word.feats) for word in sentence.words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.build_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.dependencies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.filter_templates(matches=\"softredirect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"list of\" in wiki.filter_templates(matches=\"DEFAULTSORT\")[0].name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dict\n",
    "d = {col: [] for col in cols}\n",
    "df = pd.DataFrame(columns=cols)\n",
    "# parse page\n",
    "# wiki = mwparserfromhell.parse(page[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [None, \"3\", \"None\", \"6\", None, None,\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d[cols[i]].append(t[i]) for i in range(len(t))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page title\n",
    "# d[\"title\"].append(page[0])\n",
    "df[\"title\"] = [page[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining article type\n",
    "if page[2] != None:\n",
    "    # d[\"type\"].append(\"redirect\")\n",
    "    df[\"type\"] = [\"redirect\"]\n",
    "else:\n",
    "    # d[\"type\"].append(\"article\")\n",
    "    df[\"type\"] = [\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting article categories\n",
    "# d[\"categories\"].append(\n",
    "#     \"|\".join([\n",
    "#         list(filter(None, x.title.split(\":\")))[-1]\n",
    "#         for x in wiki.filter_wikilinks(matches=\"category\")\n",
    "#     ]))\n",
    "df[\"categories\"] = [\"|\".join([\n",
    "        list(filter(None, x.title.split(\":\")))[-1]\n",
    "        for x in wiki.filter_wikilinks(matches=\"category\")\n",
    "    ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikilinks, removing links to Category items\n",
    "# d[\"wikilinks\"].append(\"|\".join(\n",
    "#     [link.title.strip_code().strip() for link in wiki.filter_wikilinks() if \"Category:\" not in link.title.strip_code().strip()]))\n",
    "\n",
    "df[\"wikilinks\"] = [\"|\".join(\n",
    "    [link.title.strip_code().strip() for link in wiki.filter_wikilinks() if \"Category:\" not in link.title.strip_code().strip()])]\n",
    "\n",
    "# external links\n",
    "# df[\"ext_links\"] = \"|\".join([link.url.strip_code().strip() for link in wiki.filter_external_links()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for infobox template name\n",
    "box = None\n",
    "for template in wiki.filter_templates():\n",
    "    if template.name.strip() in infoboxes:\n",
    "        box = wiki.filter_templates(matches=template.name.strip())[0]\n",
    "        # d[\"infobox_name\"].append(template.name.strip())\n",
    "        df[\"infobox_name\"] = [template.name.strip()]\n",
    "        break\n",
    "\n",
    "a = \"|\".join([\"{}:{}\".format(param.name.strip_code().strip(),\n",
    "                            param.value.strip_code(keep_template_params=True).strip()) for param in box.params])\n",
    "# d[\"infobox\"].append(cleanhtml(a))\n",
    "df[\"infobox\"] = [cleanhtml(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"infobox\"][0].split(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"wikilinks\"][0].split(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mais proximo da solucao definitiva\n",
    "for param in box.params:\n",
    "    for x in param.value.filter_templates():\n",
    "        print([y.value.strip_code() for y in x.params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box.params.strip_code()\n",
    "for param in box.params:\n",
    "    # print(param.value.filter_text())\n",
    "    # print(param.value.filter_wikilinks())\n",
    "    print(param.value.strip_code(keep_template_params=True).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"infobox\"][0]"
   ]
  }
 ]
}